kernel_size = c(3,3),
activation = 'relu',
input_shape = c(100, 100, 3)) %>%
layer_conv_2d(filters = 32,
kernel_size = c(3,3),
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
compile(loss = 'MSE',
optimizer = optimizer_rmsprop())
summary(model)
history <- model %>% fit(
x_train, y_train,
epochs = 30, batch_size = 128,
validation_split = 0.2
)
x_train <- array_reshape(x_train, c(nrow(x_train), 784))
x_test <- array_reshape(x_test, c(nrow(x_test), 784))
history <- model %>% fit(
x_train, y_train,
epochs = 30, batch_size = 128,
validation_split = 0.2
)
x_train
str(x_train <- array_reshape(x_train, c(nrow(x_train), 784))
x_test <- array_reshape(x_test, c(nrow(x_test), 784)))
str(x_train)
model <- keras_model_sequential()
model %>%
layer_conv_2d(filters = 32,
kernel_size = c(3,3),
activation = 'relu',
input_shape = 60000) %>%
layer_conv_2d(filters = 32,
kernel_size = c(3,3),
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
compile(loss = 'MSE',
optimizer = optimizer_rmsprop())
model <- keras_model_sequential()
model %>%
layer_conv_2d(filters = 32,
kernel_size = c(3,3),
activation = 'relu') %>%
layer_conv_2d(filters = 32,
kernel_size = c(3,3),
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
compile(loss = 'MSE',
optimizer = optimizer_rmsprop())
summary(model)
mnist <- dataset_mnist()
x_train <- mnist$train$x
y_train <- mnist$train$y
str(x_train)
model <- keras_model_sequential()
model %>%
layer_conv_2d(filters = 32,
kernel_size = c(3,3),
activation = 'relu',
input_shape = c(28, 28)) %>%
layer_conv_2d(filters = 32,
kernel_size = c(3,3),
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
compile(loss = 'MSE',
optimizer = optimizer_rmsprop())
model %>%
layer_conv_1d(filters = 32,
kernel_size = c(3,3),
activation = 'relu',
input_shape = c(28, 28)) %>%
layer_conv_1d(filters = 32,
kernel_size = c(3,3),
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
compile(loss = 'MSE',
optimizer = optimizer_rmsprop())
model %>%
layer_conv_1d(filters = 32,
kernel_size = c(3,3),
activation = 'relu',
input_shape = c(28, 28)) %>%
layer_conv_1d(filters = 32,
kernel_size = 3,
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
compile(loss = 'MSE',
optimizer = optimizer_rmsprop())
model <- keras_model_sequential()
model %>%
layer_conv_1d(filters = 32,
kernel_size = 3,
activation = 'relu',
input_shape = c(28, 28)) %>%
layer_conv_1d(filters = 32,
kernel_size = 3,
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
compile(loss = 'MSE',
optimizer = optimizer_rmsprop())
?layer_conv_1d
model <- keras_model_sequential()
model %>%
layer_conv_2d(filters = 32,
kernel_size = 3,
activation = 'relu',
input_shape = c(28, 28)) %>%
layer_conv_1d(filters = 32,
kernel_size = 3,
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
compile(loss = 'MSE',
optimizer = optimizer_rmsprop())
model %>%
layer_conv_2d(filters = 32,
kernel_size = 3,
activation = 'relu',
input_shape = c(28, 28)) %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
compile(loss = 'MSE',
optimizer = optimizer_rmsprop())
model <- keras_model_sequential()
model %>%
layer_conv_2d(filters = 32,
kernel_size = 3,
activation = 'relu',
input_shape = c(28, 28)) %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
compile(loss = 'MSE',
optimizer = optimizer_rmsprop())
model %>%
layer_conv_2d(filters = 10,
kernel_size = 3,
activation = 'relu',
input_shape = c(28, 28)) %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
compile(loss = 'MSE',
optimizer = optimizer_rmsprop())
model <- keras_model_sequential()
model %>%
layer_conv_2d(filters = 10,
kernel_size = 3,
activation = 'relu',
input_shape = c(28, 28)) %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
compile(loss = 'MSE',
optimizer = optimizer_rmsprop())
model %>%
layer_conv_1d(filters = 10,
kernel_size = 3,
activation = 'relu',
input_shape = c(28, 28)) %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
compile(loss = 'MSE',
optimizer = optimizer_rmsprop())
model %>%
layer_conv_2d(filters = 10,
kernel_size = 3,
activation = 'relu',
input_shape = c(28, 28)) %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
compile(loss = 'MSE',
optimizer = optimizer_rmsprop())
model <- keras_model_sequential()
model %>%
layer_conv_2d(filters = 10,
kernel_size = 3,
activation = 'relu',
input_shape = c(28, 28)) %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
compile(loss = 'MSE',
optimizer = optimizer_rmsprop())
cifar <- dataset_cifar10()
train_data <- scale(cifar$train$x)
gc()
dim(train_data) <- c(50000,32,32,3)
class_names <- c('airplane', 'automobile', 'bird', 'cat', 'deer',
'dog', 'frog', 'horse', 'ship', 'truck')
cifar$train$x[1]
cifar$train$x[1:30]
cifar$train$x[index,,,]
index <- 1:30
cifar$train$x[index,,,]
cifar$train$x[index,,,] %>%
purrr::array_tree(1) %>%
purrr::set_names(class_names[cifar$train$y[index] + 1]) %>%
purrr::map(as.raster, max = 255) %>%
purrr::iwalk(~{plot(.x); title(.y)})
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu", input_shape = c(32,32,3)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2))
summary(model)
model %>% compile(
optimizer = "adam",
loss = "sparse_categorical_crossentropy",
metrics = "accuracy"
)
str(train_data)
train_label <- as.numeric(cifar$train$y)
dim(train_label) <- c(50000)
history
history <- model %>%
fit(
x = train_data, y = train_label,
epochs = 50,
validation_split=0.2,
use_multiprocessing=TRUE
)
summary(model)
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu", input_shape = c(32,32,3)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_flatten()
summary(model)
model %>% compile(
optimizer = "adam",
loss = "sparse_categorical_crossentropy",
metrics = "accuracy"
)
history <- model %>%
fit(
x = train_data, y = train_label,
epochs = 50,
validation_split=0.2,
use_multiprocessing=TRUE
)
history <- model %>%
fit(
x = train_data, y = train_label,
epochs = 1,
validation_split=0.2,
use_multiprocessing=TRUE
)
summary(history)
str9history
str(history)
model
6*6*64
model$variables
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu", input_shape = c(32,32,3)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_flatten()
model$variables
str(model$variables)
model$outputs
history$metrics
history$params
model %>%
fit(
x = train_data, y = train_label,
epochs = 1,
validation_split=0.2,
use_multiprocessing=TRUE
)
model %>% compile(
optimizer = "adam",
loss = "sparse_categorical_crossentropy",
metrics = "accuracy"
)
model$output
history <- model %>%
fit(
x = head(train_data, 1000), y = head(train_label, 1000),
epochs = 1,
validation_split=0.2,
use_multiprocessing=TRUE
)
str(train_data)
head(train_data)
history <- model %>%
fit(
x = train_data[1:1000, 1:32, 1:32, 1:3], y = train_label[1:1000, 1:32, 1:32, 1:3],
epochs = 1,
validation_split=0.2,
use_multiprocessing=TRUE
)
train_label[1:1000, 1:32, 1:32, 1:3]
train_label
str(train_label)
train_label[1:1000]
history <- model %>%
fit(
x = train_data[1:1000, 1:32, 1:32, 1:3], y = train_label[1:1000],
epochs = 1,
validation_split=0.2,
use_multiprocessing=TRUE
)
history$params
model$variables
model$output
model$outputs
model$outbound_nodes
model$output_mask
model$compute_output_shape
model$get_output_at
model$get_input_at(1)
model$get_input_at(0)
model$get_input_at(1.2)
model$get_output_at(1)
model$get_output_at
model$outputs
model$outputs[[1]]
l <- intermediate_layer_model %>% get_layer(layer_name)
# there is just one input node, so index = 0
# shape=(?, 150)
l$get_input_at(0L)
layer_name<-"dense_1"
model$input
layer_name
intermediate_layer_model <- keras_model(inputs = model$input, outputs = get_layer(model, layer_name)$output)
summary(model)
layer_name<-"flatten_4"
intermediate_layer_model <- keras_model(inputs = model$input, outputs = get_layer(model, layer_name)$output)
intermediate_layer_model
l <- intermediate_layer_model %>% get_layer(layer_name)
l
l$get_input_at(0L)
model$get_output_at(0L)
model$get_output_at(0L)
as.numeric(model$get_output_at(0L))
model$get_weights
model$get_weights()
w = model$get_weights()
w
summary(model)
w = model$get_weights("flatten_4")
w = model$get_weights()
w
w[[6]]
summary(model)
w[[5]]
w[[1]]
w[[6]]
w[[7]]
w[[6]]
summary(model)
w[[1]]
summary(model)
w[[1]]
summary(model)
3*3*32
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu", input_shape = c(32,32,3)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_flatten() %>%
compile(
optimizer = "adam",
loss = "sparse_categorical_crossentropy",
metrics = "accuracy"
)
summary(model)
model$get_weights()
w[[5]]
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu", input_shape = c(32,32,3)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_flatten() %>%
compile(
optimizer = "adam",
loss = "sparse_categorical_crossentropy",
metrics = "accuracy"
) %>%
fit(
x = train_data[1:1000, 1:32, 1:32, 1:3], y = train_label[1:1000],
epochs = 1,
validation_split=0.2,
use_multiprocessing=TRUE
)
summary(model)
w[[5]]
dim(w[[6]])
summary(model)
?layer_flatten
w = model$get_weights()
model$get_weights()
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu", input_shape = c(32,32,3)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_flatten() %>%
compile(
optimizer = "adam",
loss = "sparse_categorical_crossentropy",
metrics = "accuracy") %>%
fit(
x = train_data[1:1000, 1:32, 1:32, 1:3], y = train_label[1:1000],
epochs = 1,
validation_split=0.2,
use_multiprocessing=TRUE
)
model$get_weights()
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu", input_shape = c(32,32,3)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_flatten() %>%
compile(
optimizer = "adam",
loss = "sparse_categorical_crossentropy",
metrics = "accuracy")
model %>%
fit(
x = train_data[1:1000, 1:32, 1:32, 1:3], y = train_label[1:1000],
epochs = 1,
validation_split=0.2,
use_multiprocessing=TRUE
)
model$weights
model$weights[[5]]
str(model$weights[[5]])
summary(model$weights[[5]])
model$get_layer("flatten_4")
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu", input_shape = c(32,32,3)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_flatten() %>%
compile(
optimizer = "adam",
loss = "sparse_categorical_crossentropy",
metrics = "accuracy")
summary(model)
98*32
summary(model)
history
model$get_layer("flatten_4")
model$get_layer("flatten_9")
w[[6]]
w[[5]]
summary(model)
w[[1]]
w[[2]]
summary(model)
w[[5]]
length(w[[5]])
dim(w[[5]])
summary(model)
dim(w[[1]])
dim(w[[1]])[1]
dim(w[[1]])
(w[[1]])
(w[[1]])[,,1,1]
dim(w[[2]])
w[[2]]
summary(model)
98*98
9*98
9*98+32
9*98+3
896-882
1+1
3+3+3+32
3*3*3*32
3*3*3*32+32
3*3*32*64+64
summary(model)
layer_name <- 'flatten_9'
intermediate_layer_model <- keras_model(inputs = model$input,
outputs = get_layer(model, layer_name)$output)
intermediate_output <- predict(intermediate_layer_model, train_data[1:1000, 1:32, 1:32, 1:3])
intermediate_output
length(intermediate_output)
intermediate_output[1]
intermediate_output[1,]
hist(intermediate_output[1,])
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu", input_shape = c(32,32,3), name = "hello") %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_flatten() %>%
compile(
optimizer = "adam",
loss = "sparse_categorical_crossentropy",
metrics = "accuracy")
summary(model)
history = model %>%
fit(
x = train_data[1:1000, 1:32, 1:32, 1:3], y = train_label[1:1000],
epochs = 1,
validation_split=0.2,
use_multiprocessing=TRUE
)
model$get_layer("hello")
layer_name <- 'hello'
intermediate_layer_model <- keras_model(inputs = model$input,
outputs = get_layer(model, layer_name)$output)
intermediate_output <- predict(intermediate_layer_model, train_data[1:1000, 1:32, 1:32, 1:3])
intermediate_output
